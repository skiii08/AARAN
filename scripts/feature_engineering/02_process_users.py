"""
Phase 1-2 æœ€çµ‚ä¿®æ­£ç‰ˆ: Person Embeddingä¿®æ­£ (ãƒ­ãƒã‚¹ãƒˆå‡¦ç†é©ç”¨)
é…ç½®: scripts/feature_engineering/02_process_users.py

æœ€çµ‚ä¿®æ­£å†…å®¹:
- get_person_embeddingé–¢æ•°ã¯ãƒã‚¹ãƒˆæ§‹é€ ã¨å¤§æ–‡å­—å°æ–‡å­—ã«å¯¾å¿œæ¸ˆã¿ã€‚
- compute_top_k_embeddingé–¢æ•°ã‚’ãƒ­ãƒã‚¹ãƒˆåŒ–ã—ã€Top-Kå€™è£œè€…ãƒªã‚¹ãƒˆã‹ã‚‰åŸ‹ã‚è¾¼ã¿ãŒNoneã®äººåï¼ˆOOVï¼‰ã‚’ç¢ºå®Ÿã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã€æœ‰åŠ¹ãªåŸ‹ã‚è¾¼ã¿ã®ã¿ã§å¹³å‡ã‚’è¨ˆç®—ã™ã‚‹ã€‚
- ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ã¯ç’°å¢ƒä¾å­˜ã§åæ˜ ã•ã‚Œãªã„ãŸã‚ã€tqdm.writeã‚’ä½¿ç”¨ã™ã‚‹å½¢ã«ä¿®æ­£ã—ã¤ã¤ã€ä¸»è¦ãªãƒ­ã‚¸ãƒƒã‚¯ã‚’ä¿®æ­£ã€‚
"""

import pandas as pd
import numpy as np
import torch
import json
from pathlib import Path
from collections import defaultdict
from tqdm import tqdm
from scipy.stats import entropy
import warnings

warnings.filterwarnings('ignore')

# ==================== Config ====================
BASE_DIR = Path(__file__).resolve().parent.parent.parent
DATA_DIR = BASE_DIR / "data"
RAW_DIR = DATA_DIR / "raw"
PROCESSED_DIR = DATA_DIR / "processed"

USERS_CSV = RAW_DIR / "users.csv"
REVIEWS_CSV = RAW_DIR / "reviews.csv"
MOVIE_ENTITIES_JSON = PROCESSED_DIR / "movie_entities.json"
USER_PERSON_COUNTS_JSON = PROCESSED_DIR / "user_person_counts.json"
ENTITY_EMBEDDINGS_PT = PROCESSED_DIR / "entity_embeddings.pt"

ASPECT_NAMES = [
    'acting_performance', 'artistic_design', 'audio_music',
    'casting_choices', 'character_development', 'commercial_context',
    'comparative_analysis', 'editing_pacing', 'emotion',
    'expectation', 'filmmaking_direction', 'genre_style',
    'recommendation', 'story_plot', 'technical_visuals',
    'themes_messages', 'viewing_experience', 'writing_dialogue'
]

GENRE_NAMES = [
    'Action', 'Adventure', 'Animation', 'Comedy', 'Crime', 'Documentary',
    'Drama', 'Family', 'Fantasy', 'History', 'Horror', 'Music',
    'Mystery', 'Romance', 'Science Fiction', 'TV Movie', 'Thriller', 'War', 'Western'
]

# ==================== Load Data ====================
print("=" * 70)
print("PHASE 1-2 FIXED: USER FEATURE ENGINEERING (686D)")
print("=" * 70)
print("\nLoading data...")

users_df = pd.read_csv(USERS_CSV)
reviews_df = pd.read_csv(REVIEWS_CSV)

with open(MOVIE_ENTITIES_JSON, 'r', encoding='utf-8') as f:
    movie_entities_list = json.load(f)
movie_entities = {m['movie_id']: m for m in movie_entities_list}

with open(USER_PERSON_COUNTS_JSON, 'r', encoding='utf-8') as f:
    user_person_counts = json.load(f)

# weights_only=False ã¯éæ¨å¥¨ã®ãŸã‚å‰Šé™¤ã—ã€ã“ã“ã§ã¯ãã®ã¾ã¾ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™
entity_embeddings = torch.load(ENTITY_EMBEDDINGS_PT)

print(f"âœ“ Users: {len(users_df)}")
print(f"âœ“ Reviews: {len(reviews_df)}")
print(f"âœ“ Movies: {len(movie_entities)}")
print(f"âœ“ User-Person counts: {len(user_person_counts)} users")
print(f"âœ“ Entity embeddings keys: {len(entity_embeddings)}")

# Check embedding structure
sample_keys = list(entity_embeddings.keys())[:5]
print(f"  Sample keys: {sample_keys}")

# ==================== 1. BUILD PERSON SETS ====================
print("\n" + "=" * 70)
print("1. BUILDING ACTOR/DIRECTOR SETS FROM METADATA")
print("=" * 70)

all_actors_set = set()
all_directors_set = set()

for movie in movie_entities.values():
    for actor in movie['actors']:
        all_actors_set.add(actor.lower())
    for director in movie['directors']:
        all_directors_set.add(director.lower())

print(f"âœ“ Unique actors: {len(all_actors_set)}")
print(f"âœ“ Unique directors: {len(all_directors_set)}")

overlap = all_actors_set & all_directors_set
print(f"âœ“ Overlap (actor & director): {len(overlap)}")

# ==================== 2. CLASSIFY PERSONS ====================
print("\n" + "=" * 70)
print("2. CLASSIFYING PERSON NAMES (Actor vs Director)")
print("=" * 70)

user_actors = {}
user_directors = {}

for user_name, person_dict in user_person_counts.items():
    actors_dict = {}
    directors_dict = {}

    for person_name, count in person_dict.items():
        person_lower = person_name.lower()

        is_actor = person_lower in all_actors_set
        is_director = person_lower in all_directors_set

        if is_actor and is_director:
            if overlap and person_lower in overlap:
                actors_dict[person_name] = count
                directors_dict[person_name] = count
        elif is_actor:
            actors_dict[person_name] = count
        elif is_director:
            directors_dict[person_name] = count

    if actors_dict:
        user_actors[user_name] = actors_dict
    if directors_dict:
        user_directors[user_name] = directors_dict

print(f"âœ“ Users with actor preferences: {len(user_actors)}")
print(f"âœ“ Users with director preferences: {len(user_directors)}")

# ==================== 3. COMPUTING PERSON PREFERENCE EMBEDDINGS (FIXED) ====================
print("\n" + "=" * 70)
print("3. COMPUTING PERSON PREFERENCE EMBEDDINGS (FINAL ROBUST FIX)")
print("=" * 70)

# ----------------- ğŸš¨ OOVäººåç‰¹å®šãƒ­ã‚¸ãƒƒã‚¯ ğŸš¨ -----------------
# 1. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å¥½ã¾ã‚Œã¦ã„ã‚‹ã™ã¹ã¦ã®äººåï¼ˆå°æ–‡å­—ï¼‰ã‚’æŠ½å‡º
all_user_persons = set()
for person_dict in user_person_counts.values():
    for person_name in person_dict.keys():
        all_user_persons.add(person_name.lower())

# 2. åŸ‹ã‚è¾¼ã¿ãŒã‚ã‚‹ã™ã¹ã¦ã®äººåï¼ˆå°æ–‡å­—ï¼‰ã‚’æŠ½å‡º
all_embedded_persons = set()
for person_key in ['actors', 'directors']:
    if person_key in entity_embeddings:
        for embedded_name in entity_embeddings[person_key].keys():
            all_embedded_persons.add(embedded_name.lower())

# 3. OOVäººåï¼ˆåŸ‹ã‚è¾¼ã¿ãŒãªã„äººåï¼‰ã‚’ç‰¹å®š
oov_persons = sorted(list(all_user_persons - all_embedded_persons))

print(f"\nğŸ›‘ CRITICAL DEBUG: Total OOV Persons (User-Preferred but No Embedding): {len(oov_persons)}")
if len(oov_persons) > 0:
    # OOVäººåãŒå¤šã™ãã‚‹å ´åˆã¯ã€æœ€åˆã®20äººã®ã¿è¡¨ç¤º
    print(f"  Sample OOV Persons (First 20): {oov_persons[:20]}")
    print(f"  --- OOV Count Check: Actor (Users: {len(user_actors)}) / Director (Users: {len(user_directors)}) ---")
# ----------------- ğŸš¨ OOVäººåç‰¹å®šãƒ­ã‚¸ãƒƒã‚¯çµ‚äº† ğŸš¨ -----------------

TOP_K_ACTORS = 5
TOP_K_DIRECTORS = 3
EMBEDDING_DIM = 300


def get_person_embedding(person_name, entity_type='actor'):
    """
    Get embedding for a person (actor/director) from entity_embeddings.
    FIXED: Handles nested dictionary structure and case inconsistency.
    """
    entity_key = entity_type + 's' # 'actor' -> 'actors', 'director' -> 'directors'

    # 1. ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã®ã‚­ãƒ¼ã§è¾æ›¸ã‚’å–å¾— (ä¾‹: entity_embeddings['actors'])
    if entity_key not in entity_embeddings:
        return None

    person_map = entity_embeddings[entity_key]

    # 2. user_person_countsã‹ã‚‰ã®ã‚­ãƒ¼ã¯å°æ–‡å­— (ä¾‹: 'john goodman')
    person_name_lower = person_name.lower()

    # 3. åŸ‹ã‚è¾¼ã¿ãƒãƒƒãƒ—å†…ã®ã‚­ãƒ¼ (ä¾‹: 'John Goodman') ã¨å°æ–‡å­—ã§æ¯”è¼ƒã—ã¦ã€ä¸€è‡´ã™ã‚‹å…ƒã®ã‚­ãƒ¼ã‚’æ¢ã™
    found_key = None
    for original_key in person_map.keys():
        if original_key.lower() == person_name_lower:
            found_key = original_key
            break

    if found_key:
        emb = person_map[found_key]
        if isinstance(emb, torch.Tensor):
            return emb.numpy()
        # 01_process_movies.pyã§tolist()ã«å¤‰æ›ã•ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚
        return np.array(emb)

    return None


def compute_top_k_embedding(person_dict, entity_type, top_k):
    """
    [æœ€çµ‚ãƒ­ãƒã‚¹ãƒˆç‰ˆ]
    Top-Kã®å€™è£œè€…ã‹ã‚‰ã€åŸ‹ã‚è¾¼ã¿ãŒå­˜åœ¨ã™ã‚‹äººåã®ã¿ã‚’æŠ½å‡ºã—ã€ãã®å¹³å‡ã‚’è¨ˆç®—ã™ã‚‹ã€‚
    åŸ‹ã‚è¾¼ã¿ãŒãªã„äººåã¯ã‚µã‚¤ãƒ¬ãƒ³ãƒˆã«ç„¡è¦–ã•ã‚Œã€ã‚«ã‚¦ãƒ³ãƒˆæ•°ã«åæ˜ ã•ã‚Œã‚‹ã€‚
    """
    if len(person_dict) == 0:
        return np.zeros(EMBEDDING_DIM), 0, []

    # 1. è©•ä¾¡å›æ•°ã«åŸºã¥ã„ã¦Top-Kã®äººåã‚’å–å¾—
    sorted_persons = sorted(person_dict.items(), key=lambda x: -x[1])[:top_k]

    embeddings = []
    missing_persons = []  # OOV/æ¬ æäººåã‚’è¿½è·¡

    # 2. Top-Kã®å„äººåã«ã¤ã„ã¦åŸ‹ã‚è¾¼ã¿ã‚’å–å¾—ã—ã€Noneï¼ˆåŸ‹ã‚è¾¼ã¿ãªã—ï¼‰ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    for person, count in sorted_persons:
        emb = get_person_embedding(person, entity_type)
        if emb is not None:
            embeddings.append(emb)
        else:
            missing_persons.append(person)  # æ¬ æäººåã‚’ãƒªã‚¹ãƒˆã«è¿½åŠ 

    if len(embeddings) == 0:
        # åŸ‹ã‚è¾¼ã¿ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸå ´åˆã€ã‚¼ãƒ­ãƒ™ã‚¯ãƒˆãƒ«ã‚’è¿”ã™
        return np.zeros(EMBEDDING_DIM), 0, missing_persons  # <-- æ¬ æäººåãƒªã‚¹ãƒˆã‚’è¿”ã™
    # ...
    # 3. åŸ‹ã‚è¾¼ã¿ãŒè¦‹ã¤ã‹ã£ãŸäººåã®å¹³å‡ã‚’è¨ˆç®—ã—ã€è¦‹ã¤ã‹ã£ãŸæ•°(count)ã¨æ¬ æäººåãƒªã‚¹ãƒˆã‚’è¿”ã™
    return np.mean(embeddings, axis=0), len(embeddings), missing_persons  # <-- æ¬ æäººåãƒªã‚¹ãƒˆã‚’è¿”ã™


# Compute for all users
fav_actor_vectors = []
fav_actor_counts = []
fav_director_vectors = []
fav_director_counts = []

print(f"Computing Top-{TOP_K_ACTORS} actor embeddings...")
found_actor_users = 0
for user_name in tqdm(users_df['user_name'], desc="Actors"):
    if user_name in user_actors:
        # 3ã¤ã®è¿”ã‚Šå€¤ã‚’å—ã‘å–ã‚‹ (vec, count, missing_persons)
        vec, count, missing_persons = compute_top_k_embedding(user_actors[user_name], 'actor', TOP_K_ACTORS)

        # --- ğŸš¨ CRITICAL DEBUG INSERTION ğŸš¨ ---
        # å®Œå…¨ã«å¤±æ•—ã—ãŸ91äººã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’ç‰¹å®šã™ã‚‹
        if count == 0:
            tqdm.write(f"\nğŸ›‘ CRITICAL FAIL (Count=0): User '{user_name}'")
            tqdm.write(f"  Top-{TOP_K_ACTORS} persons are ALL missing embeddings: {missing_persons}")
        # --- ğŸš¨ CRITICAL DEBUG INSERTION END ğŸš¨ ---

        if count > 0:
            found_actor_users += 1
    else:
        vec, count = np.zeros(EMBEDDING_DIM), 0
    fav_actor_vectors.append(vec)
    fav_actor_counts.append(count)

print(f"  âœ“ Found embeddings for {found_actor_users} users")

print(f"Computing Top-{TOP_K_DIRECTORS} director embeddings...")
found_director_users = 0
for user_name in tqdm(users_df['user_name'], desc="Directors"):
    if user_name in user_directors:
        # 3ã¤ã®è¿”ã‚Šå€¤ã‚’å—ã‘å–ã‚‹ãŒã€3ã¤ç›®ã¯ä½¿ç”¨ã—ãªã„ ([]ãŒè¿”ã£ã¦ãã‚‹)
        vec, count, _ = compute_top_k_embedding(user_directors[user_name], 'director', TOP_K_DIRECTORS)

        # ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ã¯ã€ãƒ‡ãƒãƒƒã‚°ã®å•é¡ŒãŒè§£æ¶ˆã•ã‚Œãªã„ãŸã‚ã€ä»Šå›ã¯å‰²æ„›ã—ã¾ã™ã€‚

        if count > 0:
            found_director_users += 1
    else:
        vec, count = np.zeros(EMBEDDING_DIM), 0
    fav_director_vectors.append(vec)
    fav_director_counts.append(count)

print(f"  âœ“ Found embeddings for {found_director_users} users")

fav_actor_vectors = np.array(fav_actor_vectors)
fav_actor_counts = np.array(fav_actor_counts)
fav_director_vectors = np.array(fav_director_vectors)
fav_director_counts = np.array(fav_director_counts)

print(f"\nâœ“ Actor vectors: {fav_actor_vectors.shape}")
print(f"âœ“ Director vectors: {fav_director_vectors.shape}")
# **ã“ã®å€¤ãŒæ”¹å–„ã•ã‚Œã‚‹ã‹ã‚’ç¢ºèªã—ã¾ã™**
print(f"âœ“ Avg actors per user: {fav_actor_counts.mean():.2f}")
print(f"âœ“ Avg directors per user: {fav_director_counts.mean():.2f}")
print(f"âœ“ Non-zero actor embeddings: {(fav_actor_counts > 0).sum()} / {len(fav_actor_counts)}")
print(f"âœ“ Non-zero director embeddings: {(fav_director_counts > 0).sum()} / {len(fav_director_counts)}")

# ==================== ç¶šã: å…ƒã®ã‚³ãƒ¼ãƒ‰ã¨åŒã˜ ====================
# (Genre preferences, Temporal features ãªã©)

# Aspect features
aspect_zscore_cols = [f'zscore_{aspect}' for aspect in ASPECT_NAMES]
aspect_sentiment_cols = [f'sentiment_{aspect}' for aspect in ASPECT_NAMES]

aspect_zscore = users_df[aspect_zscore_cols].fillna(0).values
aspect_sentiment = users_df[aspect_sentiment_cols].fillna(3.0).values

# Review stats
user_stats = reviews_df.groupby('user_name').agg({
    'rating_raw': ['count', 'mean', 'std', 'min', 'max']
}).reset_index()
user_stats.columns = ['user_name', 'review_count', 'rating_mean', 'rating_std', 'rating_min', 'rating_max']
users_merged = users_df.merge(user_stats, on='user_name', how='left')

review_count = users_merged['review_count'].fillna(0).values
rating_mean = users_merged['rating_mean'].fillna(users_merged['rating_mean'].mean()).values
rating_std = users_merged['rating_std'].fillna(0).values
rating_min = users_merged['rating_min'].fillna(0).values
rating_max = users_merged['rating_max'].fillna(0).values

review_stats = np.column_stack([review_count, rating_mean, rating_std, rating_min, rating_max])

# Genre preferences
genre_rating_cols = [f'rating_{genre}' for genre in GENRE_NAMES]
genre_count_cols = [f'count_{genre}' for genre in GENRE_NAMES]

genre_ratings = users_df[genre_rating_cols].fillna(0).values
genre_counts = users_df[genre_count_cols].fillna(0).values
genre_counts_norm = genre_counts / (genre_counts.sum(axis=1, keepdims=True) + 1e-8)

# Genre diversity
genre_diversity = []
for i in range(len(users_df)):
    counts = genre_counts[i]
    if counts.sum() > 0:
        probs = counts / counts.sum()
        probs = probs[probs > 0]
        div = entropy(probs)
    else:
        div = 0.0
    genre_diversity.append(div)
genre_diversity = np.array(genre_diversity)

# Temporal
if 'first_date' in users_df.columns and 'last_date' in users_df.columns:
    users_df['first_date'] = pd.to_datetime(users_df['first_date'], errors='coerce')
    users_df['last_date'] = pd.to_datetime(users_df['last_date'], errors='coerce')
    active_days = (users_df['last_date'] - users_df['first_date']).dt.days.fillna(0).values
    review_count_raw = users_df['review_count_raw'].fillna(users_df['review_count_raw'].mean()).values
    review_velocity = review_count_raw / (active_days + 1)
else:
    active_days = np.zeros(len(users_df))
    review_velocity = np.zeros(len(users_df))

# Rating vs global
global_mean = reviews_df['rating_raw'].mean()
rating_vs_global = rating_mean - global_mean

# Sentiment overall
sentiment_overall = aspect_sentiment.mean(axis=1)

# ==================== COMBINE FEATURES ====================
print("\n" + "=" * 70)
print("COMBINING ALL FEATURES")
print("=" * 70)

user_features = np.concatenate([
    aspect_zscore,           # 18D
    aspect_sentiment,        # 18D
    review_stats,            # 5D
    fav_actor_vectors,       # 300D âœ¨ FIXED
    fav_actor_counts.reshape(-1, 1),  # 1D
    fav_director_vectors,    # 300D âœ¨ FIXED
    fav_director_counts.reshape(-1, 1),  # 1D
    genre_ratings,           # 19D
    genre_counts_norm,       # 19D
    genre_diversity.reshape(-1, 1),   # 1D
    active_days.reshape(-1, 1),       # 1D
    review_velocity.reshape(-1, 1),   # 1D
    rating_vs_global.reshape(-1, 1),  # 1D
    sentiment_overall.reshape(-1, 1)  # 1D
], axis=1)

print(f"âœ“ Combined shape: {user_features.shape}")
print(f"  Expected: (N, 686)")

# ==================== SAVE ====================
output_dict = {
    'features': torch.tensor(user_features, dtype=torch.float32),
    'user_names': users_df['user_name'].values,
    'feature_dims': {
        'zscore': 18,
        'sentiment': 18,
        'stats': 5,
        'fav_actor_emb': 300,
        'fav_actor_count': 1,
        'fav_director_emb': 300,
        'fav_director_count': 1,
        'genre_ratings': 19,
        'genre_counts': 19,
        'genre_diversity': 1,
        'active_days': 1,
        'review_velocity': 1,
        'rating_vs_global': 1,
        'sentiment_overall': 1,
        'total': 686
    }
}

torch.save(output_dict, PROCESSED_DIR / "user_features.pt")
print(f"\nâœ… Saved: {PROCESSED_DIR / 'user_features.pt'}")
print("\nğŸ‰ PHASE 1-2 FIXED COMPLETE!")